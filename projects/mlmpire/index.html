<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> MLMpire | Team T. Team </title> <meta name="author" content="Team T. Team"> <meta name="description" content="392 points"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/govtech-25-ctf-writeup/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="/govtech-25-ctf-writeup/assets/libs/mdb/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/govtech-25-ctf-writeup/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/govtech-25-ctf-writeup/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="/govtech-25-ctf-writeup/assets/libs/google_fonts/google-fonts.css"> <link defer rel="stylesheet" href="/govtech-25-ctf-writeup/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/govtech-25-ctf-writeup/assets/img/team-team-logo.png?515ee9a93529f322a89c3b07c0a510dc"> <link rel="stylesheet" href="/govtech-25-ctf-writeup/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cakiki.github.io/govtech-25-ctf-writeup/projects/mlmpire/"> <script src="/govtech-25-ctf-writeup/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/govtech-25-ctf-writeup/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/govtech-25-ctf-writeup/"> <span class="font-weight-bold">Team</span> T. Team </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/govtech-25-ctf-writeup/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/govtech-25-ctf-writeup/writeups/">Writeups </a> </li> <li class="nav-item "> <a class="nav-link" href="/govtech-25-ctf-writeup/team/">Team </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">MLMpire</h1> <p class="post-description">392 points</p> </header> <article> <blockquote class="block-tip"> <h4 id="challenge">Challenge</h4> <p>An eager intern at MLMpire handed a log-normalization model more than it should have: raw server logs with passwords left in plain sight. The model still remembers. You’ve got the weights. Crack its learned memory, follow the breadcrumbs in its predictions, and pull the flag out from where it’s been quietly embedded.</p> </blockquote> <h4 id="solution">Solution</h4> <p>We can use the [MASK] token to predict the next most probable tokens and run a depth-first search, branching whenever a token probability is greater than 0.3, to extract some strings the model was trained on.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
</pre></td> <td class="code"><pre><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">GPT2Config</span>

<span class="n">SEQ_LEN</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MLMWrapper</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">s</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="sh">"</span><span class="s">[</span><span class="sh">"</span><span class="p">:</span>
                <span class="n">j</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="sh">"</span><span class="s">]</span><span class="sh">"</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="n">tok</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  
                    <span class="k">if</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">stoi</span><span class="p">:</span>
                        <span class="n">tokens</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
                        <span class="n">i</span> <span class="o">=</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span>
                        <span class="k">continue</span>
            <span class="n">tokens</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">stoi</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">stoi</span><span class="p">[</span><span class="sh">"</span><span class="s">[UNK]</span><span class="sh">"</span><span class="p">])</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">SEQ_LEN</span><span class="p">:</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">ids</span> <span class="o">+</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">stoi</span><span class="p">[</span><span class="sh">"</span><span class="s">[PAD]</span><span class="sh">"</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="n">SEQ_LEN</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[:</span><span class="n">SEQ_LEN</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">ids</span><span class="p">]).</span><span class="nf">long</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">mask_positions</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="n">mask_id</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">stoi</span><span class="p">[</span><span class="sh">"</span><span class="s">[MASK]</span><span class="sh">"</span><span class="p">]</span>
        <span class="nf">return </span><span class="p">(</span><span class="n">encoded</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">mask_id</span><span class="p">).</span><span class="nf">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">./hf_gpt2_model</span><span class="sh">"</span><span class="p">,</span> <span class="n">vocab_path</span><span class="o">=</span><span class="sh">"</span><span class="s">vocab.json</span><span class="sh">"</span><span class="p">):</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">GPT2Config</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="nc">MLMWrapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fill_mask</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="n">text_with_mask</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">wrapper</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">text_with_mask</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">mask_token_id</span> <span class="o">=</span> <span class="n">wrapper</span><span class="p">.</span><span class="n">stoi</span><span class="p">[</span><span class="sh">"</span><span class="s">[MASK]</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">mask_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">mask_token_id</span><span class="p">).</span><span class="nf">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">wrapper</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span>  
    <span class="n">pos</span> <span class="o">=</span> <span class="n">mask_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">logits_for_pos</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">pos</span><span class="p">]</span>  
    <span class="k">return</span> <span class="n">logits_for_pos</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">()</span>

<span class="n">wrapper</span> <span class="o">=</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">./hf_gpt2_model</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">vocab.json</span><span class="sh">"</span><span class="p">)</span>

<span class="n">stack</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="sh">""</span><span class="p">)]</span>
<span class="k">while</span> <span class="n">stack</span><span class="p">:</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="n">SEQ_LEN</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">continue</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="nf">fill_mask</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s">[MASK]</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">toks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">probs</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">toks</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">toks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">toks</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">wrapper</span><span class="p">.</span><span class="n">itos</span><span class="p">[</span><span class="n">tok</span><span class="p">.</span><span class="nf">item</span><span class="p">()]</span>
        <span class="n">stack</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">c</span><span class="p">))</span>
</pre></td> </tr></tbody></table></code></pre></figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/govtech-25-ctf-writeup/assets/img/mlm-480.webp 480w,/govtech-25-ctf-writeup/assets/img/mlm-800.webp 800w,/govtech-25-ctf-writeup/assets/img/mlm-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/govtech-25-ctf-writeup/assets/img/mlm.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Team T. Team. Using <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="/govtech-25-ctf-writeup/assets/libs/jquery/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/govtech-25-ctf-writeup/assets/js/bootstrap.bundle.min.js"></script> <script src="/govtech-25-ctf-writeup/assets/libs/mdb/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="/govtech-25-ctf-writeup/assets/libs/masonry/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="/govtech-25-ctf-writeup/assets/libs/imagesloaded/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/govtech-25-ctf-writeup/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="/govtech-25-ctf-writeup/assets/libs/medium_zoom/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/govtech-25-ctf-writeup/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/govtech-25-ctf-writeup/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/govtech-25-ctf-writeup/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/govtech-25-ctf-writeup/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/govtech-25-ctf-writeup/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="/govtech-25-ctf-writeup/assets/libs/mathjax/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/govtech-25-ctf-writeup/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="/govtech-25-ctf-writeup/assets/libs/polyfill/polyfill.min.js" crossorigin="anonymous"></script> <script defer src="/govtech-25-ctf-writeup/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/govtech-25-ctf-writeup/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>